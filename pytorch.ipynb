{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_CF2eBxH6f8V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim\n",
        "\n",
        "\n",
        "\n",
        "# t=torch.rand((5,3)).to('cuda:0')\n",
        "# t_cpu = t.cpu()\n",
        "# print(t_cpu.device)\n",
        "# print(t.device)\n",
        "\n",
        "# t1 = torch.tensor([1,2,3]).cuda()\n",
        "# t2 = torch.tensor([4,5,6]).cuda()\n",
        "# t3 = torch.tensor([2,3,5])\n",
        "# print(t1)\n",
        "# print(t2)\n",
        "# print(t3)\n",
        "# print(t1+t2)\n",
        "# print(t1.pow(2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d =5000\n",
        "\n",
        "\n",
        "# st = time.time()\n",
        "# a = np.random.rand(d,d)\n",
        "# b = np.random.rand(d,d)\n",
        "# C=a.dot(b) #matrix multuplication\n",
        "# ed = time.time()\n",
        "# print('Time taken by numpy', ed - st)\n",
        "\n",
        "# st = time.time()\n",
        "# a_gpu = torch.rand(d,d)\n",
        "# b_gpu = torch.rand(d,d)\n",
        "# C=torch.mm(a_gpu,b_gpu)\n",
        "# ed = time.time()\n",
        "# print('Time taken by torch', ed - st)\n",
        "\n",
        "# st = time.time()\n",
        "# a_gpu = torch.rand(d,d).cuda()\n",
        "# b_gpu = torch.rand(d,d).cuda()\n",
        "# C=torch.mm(a_gpu,b_gpu)\n",
        "# ed = time.time()\n",
        "# print('Time taken by gpu  ', ed - st)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVOZTLBq8YxI",
        "outputId": "efb01034-c7d8-4b5e-fe4c-ba6ede513621"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken by numpy 4.644192695617676\n",
            "Time taken by torch 2.2375075817108154\n",
            "Time taken by gpu   0.43155431747436523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,2,3],[4,5,6]])\n",
        "print(a)\n",
        "print(a[1,2])\n",
        "a[1,:] = 10\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka-Si8uZDBow",
        "outputId": "bf1b4572-fcbf-4597-c3cf-685c0e8c56f1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor(6)\n",
            "tensor([[ 1,  2,  3],\n",
            "        [10, 10, 10]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "me2mbZj_HcbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N= 3\n",
        "d= 1\n",
        "\n",
        "x= torch.arange(N)\n",
        "t = 2*x + (torch.rand(N)-0.5)*3\n",
        "# plt.plot(x, t, 'ro')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "w= torch.rand((d,1), requires_grad=True) #initialization\n",
        "optimizer = torch.optim.SGD([w], lr = 0.01)\n",
        "for i in range (10):\n",
        "  loss =torch.pow(x*w - t,2).mean()\n",
        "  optimizer.zero_grad()# set gradient to zero\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  # w.data =w.data - lr * w.grad\n",
        "  # w.grad = None\n",
        "  print(loss.item(), w.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yST-uaQpFugP",
        "outputId": "f5447e70-1257-483f-8bf6-bbb42fcd501d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.459794521331787 tensor([[0.9082]])\n",
            "4.1687469482421875 tensor([[0.9608]])\n",
            "3.896778106689453 tensor([[1.0116]])\n",
            "3.64263916015625 tensor([[1.0607]])\n",
            "3.4051601886749268 tensor([[1.1082]])\n",
            "3.1832497119903564 tensor([[1.1542]])\n",
            "2.975886344909668 tensor([[1.1985]])\n",
            "2.782116651535034 tensor([[1.2415]])\n",
            "2.6010496616363525 tensor([[1.2829]])\n",
            "2.4318528175354004 tensor([[1.3230]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient decent using pytorch"
      ],
      "metadata": {
        "id": "7epyeJkyNMOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim\n",
        "N = 10\n",
        "d =1\n",
        "\n",
        "x= torch.arange(N).view(-1,1).float()\n",
        "t = 2*x + (torch.rand(N)-0.5)*3\n",
        "\n",
        "\n",
        "class LR(torch.nn.Module):\n",
        "  def __init__(self,d):\n",
        "    super(LR, self).__init__()\n",
        "    self.d = d\n",
        "    self.w = torch.nn.Linear(d,1, bias =False)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.w(x)\n",
        "\n",
        "linearReg = LR(d)\n",
        "optimizer =torch.optim.SGD(linearReg.parameters(), lr = 0.01)\n",
        "for i in range(10):\n",
        "  loss = torch.pow(linearReg(x) - t, 2).mean()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(loss.item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZixqDX4zNSH1",
        "outputId": "89bce3dd-1fc2-4c7d-9ff6-bdc64478c069"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method item of Tensor object at 0x7be7c1b72e70>\n",
            "<built-in method item of Tensor object at 0x7be7ca7f5af0>\n",
            "<built-in method item of Tensor object at 0x7be7c1b72e10>\n",
            "<built-in method item of Tensor object at 0x7be7ca7f5af0>\n",
            "<built-in method item of Tensor object at 0x7be7c1b72e70>\n",
            "<built-in method item of Tensor object at 0x7be7ca7f5af0>\n",
            "<built-in method item of Tensor object at 0x7be7c1b72e10>\n",
            "<built-in method item of Tensor object at 0x7be7ca7f5af0>\n",
            "<built-in method item of Tensor object at 0x7be7c1b72e70>\n",
            "<built-in method item of Tensor object at 0x7be7ca7f5af0>\n"
          ]
        }
      ]
    }
  ]
}